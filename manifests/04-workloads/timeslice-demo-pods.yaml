apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod-$i
  namespace: gpu-timeslice-demo
spec:
  restartPolicy: Never
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule
  containers:
  - name: pytorch
    image: pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime
    command: ["python", "-c"]
    args:
    - |
      import torch
      import time
      print(f"Pod $i - GPU:", torch.cuda.get_device_name(0))
      for j in range(60):
        x = torch.randn(1000, 1000).cuda()
        y = torch.matmul(x, x)
        time.sleep(1)
      print("Done!")
    resources:
      limits:
        nvidia.com/gpu: 1
